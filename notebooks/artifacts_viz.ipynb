{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create images & videos out of saved generation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import sys\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import imageio\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import HTML\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from torch import Tensor\n",
    "\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "from utils.misc import _normalize_elements_for_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f65c75c1f10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_experiments_path = Path(\"/\", \"projects\", \"static2dynamic\", \"Thomas\", \"experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"REMOVEME_tests\"\n",
    "run_name = \"iter_inv_regen_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output dir: artifacts_viz_outputs/REMOVEME_tests/iter_inv_regen_test\n"
     ]
    }
   ],
   "source": [
    "project_path = root_experiments_path / project_name\n",
    "assert project_path.exists(), f\"Project path {project_path} does not exist.\"\n",
    "\n",
    "run_path = project_path / run_name\n",
    "assert run_path.exists(), f\"Run path {run_path} does not exist.\"\n",
    "\n",
    "output_dir = Path(\".\", \"artifacts_viz_outputs\", project_name, run_name)\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(\"output dir:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show video of trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 trajectories generated by process 0.\n",
      "Last trajectory: step_150_proc_0.pt\n"
     ]
    }
   ],
   "source": [
    "vids_path = run_path / \"saved_artifacts\" / \"trajectories\"\n",
    "assert vids_path.exists(), f\"Vids path {vids_path} does not exist.\"\n",
    "all_trajs = list(vids_path.rglob(\"*.pt\"))\n",
    "all_trajs = [x for x in all_trajs if \"proc_0\" in x.name]\n",
    "\n",
    "print(f\"Found {len(all_trajs)} trajectories generated by process 0.\")\n",
    "last_traj_path = all_trajs[-1]\n",
    "print(f\"Last trajectory: {last_traj_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trajectory with shape torch.Size([16, 5, 3, 128, 128]), dtype torch.float32 on cpu\n"
     ]
    }
   ],
   "source": [
    "last_traj = torch.load(last_traj_path, map_location=\"cpu\")\n",
    "print(f\"Loaded trajectory with shape {last_traj.shape}, dtype {last_traj.dtype} on cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomrd_vids = _normalize_elements_for_logging(\n",
    "    last_traj,\n",
    "    [\"image min-max\", \"video min-max\", \"[-1;1] raw\", \"[-1;1] clipped\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_traj_index = 1  # what sample to visualize (sample = video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm method: image min-max | saved data shape: (16, 5, 3, 128, 128) | selected video sample shape: (5, 3, 128, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"300\" controls><source src=\"artifacts_viz_outputs/REMOVEME_tests/iter_inv_regen_test/image min-max.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm method: video min-max | saved data shape: (16, 5, 3, 128, 128) | selected video sample shape: (5, 3, 128, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"300\" controls><source src=\"artifacts_viz_outputs/REMOVEME_tests/iter_inv_regen_test/video min-max.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm method: [-1;1] raw | saved data shape: (16, 5, 3, 128, 128) | selected video sample shape: (5, 3, 128, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"300\" controls><source src=\"artifacts_viz_outputs/REMOVEME_tests/iter_inv_regen_test/[-1;1] raw.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm method: [-1;1] clipped | saved data shape: (16, 5, 3, 128, 128) | selected video sample shape: (5, 3, 128, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video width=\"300\" controls><source src=\"artifacts_viz_outputs/REMOVEME_tests/iter_inv_regen_test/[-1;1] clipped.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for norm_method, vid in nomrd_vids.items():\n",
    "    print(\n",
    "        f\"Norm method: {norm_method} | saved data shape: {vid.shape} | selected video sample shape: {vid[gen_traj_index].shape}\"\n",
    "    )\n",
    "    # Convert np array to video\n",
    "    video_save_path = Path(output_dir, f\"{norm_method}.mp4\")\n",
    "    imageio.mimwrite(video_save_path, vid[gen_traj_index].transpose(0, 2, 3, 1), fps=1)\n",
    "\n",
    "    # Display the video with a specific width\n",
    "    display(HTML(f'<video width=\"300\" controls><source src=\"{video_save_path}\" type=\"video/mp4\"></video>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_transformation(t: Tensor, norm: str | None, img_size: int) -> Tensor:\n",
    "    assert t.ndim == 4, f\"Expected 4D tensor, got {t.ndim}D tensor\"\n",
    "    assert t.shape[2] == t.shape[3], f\"Expected square image, got {t.shape}\"\n",
    "    match norm:\n",
    "        case \"clip[-1;1]\":\n",
    "            # clip to [-1:1] and move to [0;1]\n",
    "            t = t.clip(-1, 1)\n",
    "            t /= 2\n",
    "            t += 0.5\n",
    "        case \"min-max\":\n",
    "            # min-max normalize to move to [0;1]\n",
    "            t -= t.amin(dim=(1, 2, 3), keepdim=True)\n",
    "            t /= t.amax(dim=(1, 2, 3), keepdim=True)\n",
    "        case \"min-max_across_times\":\n",
    "            # min-max normalize and move to [0;1]\n",
    "            t -= t.min()\n",
    "            t /= t.max()\n",
    "        case \"min-95perc_across_times\":\n",
    "            # min-max normalize to move to [0;1]\n",
    "            t -= t.min()\n",
    "            t = t.clip(0, t.to(torch.float32).quantile(0.95).item())\n",
    "            t /= t.max()\n",
    "        case None | \"None\":\n",
    "            # do nothing and let Matplotlib *clip* to [0; 1]\n",
    "            pass\n",
    "        case \"old log\":\n",
    "            t = (t.cpu().numpy() * 255).astype(np.uint8)\n",
    "        case _:\n",
    "            raise ValueError\n",
    "    # resize to img_size\n",
    "    if t.shape[2] != img_size:\n",
    "        print(f\"Resizing from {t.shape[2]} to {img_size}\")\n",
    "        t = F.interpolate(t, size=(img_size, img_size), mode=\"bilinear\", align_corners=False)\n",
    "    # order dims for matplotlib\n",
    "    t = t.permute(0, 2, 3, 1)\n",
    "    # convert to fp32 for matplotlib\n",
    "    t = t.to(torch.float32)\n",
    "    return t\n",
    "\n",
    "\n",
    "def process_index(tensor: Tensor, idx: int, norm_method: str | None, img_size: int) -> Tensor:\n",
    "    assert tensor.ndim == 5, f\"Expected 5D tensor, got {tensor.ndim}D tensor\"\n",
    "    img = tensor_transformation(tensor[idx, ...], norm_method, img_size)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frame(t: int, images: list[Tensor], temp_dir: str, nrows: int, ncols: int, tick_values: list[float]):\n",
    "    fig = plt.figure(layout=\"constrained\", figsize=(nrows * 2 + 0.2, ncols * 2))  # nrows * ncols vids + 1 progress bar\n",
    "    fig.patch.set_facecolor(\"black\")\n",
    "    title = fig.suptitle(f\"Time: {t}/{(len(images[0]) - 1)}\")\n",
    "    title.set_color(\"white\")\n",
    "    height_ratios = [1] * nrows + [0.2]  # 0.5 for the progress bar row\n",
    "    gs = GridSpec(nrows + 1, ncols, figure=fig, height_ratios=height_ratios)\n",
    "\n",
    "    # Create a progress bar artist\n",
    "    progress_bar = patches.Rectangle((0, 0.45), t / (len(images[0]) - 1), 0.1, facecolor=\"white\")\n",
    "    progress_ax = fig.add_subplot(gs[nrows, :])  # Add progress bar to the bottom row\n",
    "    progress_ax.add_patch(progress_bar)\n",
    "    progress_ax.set_xticks(tick_values)\n",
    "    progress_ax.get_yaxis().set_visible(False)\n",
    "    progress_ax.xaxis.set_tick_params(width=2, color=\"white\")\n",
    "    progress_ax.set_facecolor(\"black\")\n",
    "    progress_ax.set_xticklabels([str(idx + 1) for idx in range(len(tick_values))], color=\"white\")\n",
    "\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            ax = fig.add_subplot(gs[row, col])\n",
    "            ax.imshow(images[row * nrows + col][t])\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    # Save the frame as an image\n",
    "    plt.savefig(f\"{temp_dir}/frame_{t}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_image_sequence_video(\n",
    "    tensor_path: Path,\n",
    "    norm_method: str | None,\n",
    "    tick_values: list[float],\n",
    "    sample_idx: list[int] | None = None,\n",
    "    img_size: int = 128,\n",
    "    nrows: int = 4,\n",
    "    ncols: int = 4,\n",
    "):\n",
    "    # Load tensor\n",
    "    tensor = torch.load(tensor_path).cpu()\n",
    "    print(f\"Loaded tensor of shape {tensor.shape}\")\n",
    "\n",
    "    print(f\"Using norm method: {norm_method}, image_size: {img_size}\")\n",
    "\n",
    "    sel_samples = sample_idx if sample_idx is not None else list(range(nrows * ncols))\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        images = pool.starmap(process_index, [(tensor, idx, norm_method, img_size) for idx in sel_samples])\n",
    "\n",
    "    print(f\"Processed images; got: len(images): {len(images)}; images[0].shape: {images[0].shape}\")\n",
    "\n",
    "    # Create a temporary directory\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        with multiprocessing.Pool() as pool:\n",
    "            pool.starmap(save_frame, [(t, images, temp_dir, nrows, ncols, tick_values) for t in range(len(images[0]))])\n",
    "\n",
    "        # Compile the frames into a video using imageio\n",
    "        frames = [f\"{temp_dir}/frame_{i}.png\" for i in range(len(images[0]))]\n",
    "        print(f\"Saved {len(frames)} frames: {frames}\")\n",
    "        assert len(frames) == len(images[0]), f\"Expected {len(images[0])} frames, got {len(frames)}\"\n",
    "\n",
    "        save_path = Path(\n",
    "            \"make_traj_vids_saved_plots\", project_name, run_name, f\"{tensor_path.stem}_{norm_method}_norm.mp4\"\n",
    "        )\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        print(f\"Saving videos to {save_path}...\")\n",
    "        fps = max(int(len(images[0]) / 10), 1)\n",
    "        clip = ImageSequenceClip(frames, fps=fps)\n",
    "        clip.write_videofile(save_path.as_posix(), threads=4)\n",
    "\n",
    "    print(f\"Saved videos to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks_pos = [0.0, 0.2531645596027374, 0.5063291192054749, 0.7468354105949402, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape torch.Size([16, 10, 3, 128, 128])\n",
      "Using norm method: min-max, image_size: 128\n",
      "Processed images; got: len(images): 16; images[0].shape: torch.Size([10, 128, 128, 3])\n",
      "Saved 10 frames: ['/tmp/tmp4leanf4y/frame_0.png', '/tmp/tmp4leanf4y/frame_1.png', '/tmp/tmp4leanf4y/frame_2.png', '/tmp/tmp4leanf4y/frame_3.png', '/tmp/tmp4leanf4y/frame_4.png', '/tmp/tmp4leanf4y/frame_5.png', '/tmp/tmp4leanf4y/frame_6.png', '/tmp/tmp4leanf4y/frame_7.png', '/tmp/tmp4leanf4y/frame_8.png', '/tmp/tmp4leanf4y/frame_9.png']\n",
      "Saving videos to make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_min-max_norm.mp4...\n",
      "Moviepy - Building video make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_min-max_norm.mp4.\n",
      "Moviepy - Writing video make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_min-max_norm.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_min-max_norm.mp4\n",
      "Saved videos to make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_min-max_norm.mp4\n"
     ]
    }
   ],
   "source": [
    "create_image_sequence_video(last_traj_path, \"min-max\", ticks_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape torch.Size([16, 10, 3, 128, 128])\n",
      "Using norm method: None, image_size: 128\n",
      "Processed images; got: len(images): 16; images[0].shape: torch.Size([10, 128, 128, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 frames: ['/tmp/tmphc16kare/frame_0.png', '/tmp/tmphc16kare/frame_1.png', '/tmp/tmphc16kare/frame_2.png', '/tmp/tmphc16kare/frame_3.png', '/tmp/tmphc16kare/frame_4.png', '/tmp/tmphc16kare/frame_5.png', '/tmp/tmphc16kare/frame_6.png', '/tmp/tmphc16kare/frame_7.png', '/tmp/tmphc16kare/frame_8.png', '/tmp/tmphc16kare/frame_9.png']\n",
      "Saving videos to make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_None_norm.mp4...\n",
      "Moviepy - Building video make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_None_norm.mp4.\n",
      "Moviepy - Writing video make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_None_norm.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_None_norm.mp4\n",
      "Saved videos to make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_None_norm.mp4\n"
     ]
    }
   ],
   "source": [
    "create_image_sequence_video(last_traj_path, \"None\", ticks_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape torch.Size([16, 10, 3, 128, 128])\n",
      "Using norm method: min-max_across_times, image_size: 128\n",
      "Processed images; got: len(images): 16; images[0].shape: torch.Size([10, 128, 128, 3])\n",
      "Saved 10 frames: ['/tmp/tmp9uh3wyt0/frame_0.png', '/tmp/tmp9uh3wyt0/frame_1.png', '/tmp/tmp9uh3wyt0/frame_2.png', '/tmp/tmp9uh3wyt0/frame_3.png', '/tmp/tmp9uh3wyt0/frame_4.png', '/tmp/tmp9uh3wyt0/frame_5.png', '/tmp/tmp9uh3wyt0/frame_6.png', '/tmp/tmp9uh3wyt0/frame_7.png', '/tmp/tmp9uh3wyt0/frame_8.png', '/tmp/tmp9uh3wyt0/frame_9.png']\n",
      "Saving videos to make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_min-max_across_times_norm.mp4...\n",
      "Moviepy - Building video make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_min-max_across_times_norm.mp4.\n",
      "Moviepy - Writing video make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_min-max_across_times_norm.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_min-max_across_times_norm.mp4\n",
      "Saved videos to make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_min-max_across_times_norm.mp4\n"
     ]
    }
   ],
   "source": [
    "create_image_sequence_video(last_traj_path, \"min-max_across_times\", ticks_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape torch.Size([16, 10, 3, 128, 128])\n",
      "Using norm method: clip[-1;1], image_size: 128\n",
      "Processed images; got: len(images): 16; images[0].shape: torch.Size([10, 128, 128, 3])\n",
      "Saved 10 frames: ['/tmp/tmpbg8fv47o/frame_0.png', '/tmp/tmpbg8fv47o/frame_1.png', '/tmp/tmpbg8fv47o/frame_2.png', '/tmp/tmpbg8fv47o/frame_3.png', '/tmp/tmpbg8fv47o/frame_4.png', '/tmp/tmpbg8fv47o/frame_5.png', '/tmp/tmpbg8fv47o/frame_6.png', '/tmp/tmpbg8fv47o/frame_7.png', '/tmp/tmpbg8fv47o/frame_8.png', '/tmp/tmpbg8fv47o/frame_9.png']\n",
      "Saving videos to make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_clip[-1;1]_norm.mp4...\n",
      "Moviepy - Building video make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_clip[-1;1]_norm.mp4.\n",
      "Moviepy - Writing video make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_clip[-1;1]_norm.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_clip[-1;1]_norm.mp4\n",
      "Saved videos to make_traj_vids_saved_plots/GaussianProxy/xattn_IBENS_test/step_56400_clip[-1;1]_norm.mp4\n"
     ]
    }
   ],
   "source": [
    "create_image_sequence_video(last_traj_path, \"clip[-1;1]\", ticks_pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
